{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "003c6c86-28aa-4e66-ba32-92de5eec77a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import libraries and dependencies\n",
    "import os\n",
    "import pandas as pd\n",
    "import alpaca_trade_api as tradeapi\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#from tensorflow.keras.models import Sequential\n",
    "#from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
    "#from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from yahoo_fin.stock_info import get_data\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import xgboost as xgb\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568e2557-3a07-4d41-a12e-c391e2b358fe",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b27465a-1ac6-4822-bc9f-71d3ef61f7a1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Pull Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa2673a-7834-452e-bd50-489e540b1513",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get historical prices from first candle to the most recent candle\n",
    "hist_df = get_data('DIS', index_as_date=False)\n",
    "\n",
    "# Show the first 5 rows of our dataframe\n",
    "hist_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc957a5-c6c7-4923-b947-74157e2b3304",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create Prices DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce6990e-53cf-48ec-88d3-d9ce8b9fd849",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prices = hist_df.drop(['adjclose'], axis=1)\n",
    "prices.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671301db-6559-4844-8d66-7d498b50e3d8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create Breakout Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebd757e-d095-4ce2-8e88-77c95e05bcb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Add difference between closing price and opening price\n",
    "# NOTE: O-to-C is the length of the candle's body\n",
    "prices['O-to-C'] = prices['close'] - prices['open']\n",
    "prices['OC-20D-Mean'] = prices['O-to-C'].rolling(20).mean()\n",
    "# Calculate the % change of the current day's O-to-C relative to the moving average\n",
    "prices['OC-%-from-20D-Mean'] = 100*(prices['O-to-C'] - prices['OC-20D-Mean'])/prices['OC-20D-Mean']\n",
    "# Get the maximum OC compared to the recent 10 candles (including the current candle)\n",
    "prices['MaxOC_Prev10'] = prices['O-to-C'].rolling(10).max()\n",
    "# Add 20-Day moving average for volume \n",
    "prices['Volume-20D-Mean'] = prices['volume'].rolling(20).mean()\n",
    "# Calculate the % change of the current volume relative to the moving average\n",
    "prices['Volume-%-from-20D-Mean'] = 100*(prices['volume'] - prices['Volume-20D-Mean'])/prices['Volume-20D-Mean']\n",
    "\n",
    "# Rearrange the columns for our dataframe\n",
    "prices = prices[['ticker', 'date', 'open', 'high', 'low', 'close', \n",
    "                 'O-to-C', 'OC-20D-Mean', 'volume', 'Volume-20D-Mean', \n",
    "                 'MaxOC_Prev10', 'Volume-%-from-20D-Mean', 'OC-%-from-20D-Mean', \n",
    "                ]]\n",
    "\n",
    "#drop null values\n",
    "prices = prices.dropna()\n",
    "\n",
    "prices.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fb6c06-bd13-481d-91a3-dbfcf65bdb4e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Build the Breakout Condition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1890663-7c1a-4ef7-b6a7-53a3d1d4d6f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #Code for Breakout condition \"is green\"\n",
    "# prices['O-to-C'] >= 0.0\n",
    "# #Code for Breakout condition \"has a body that is longest in 10 days\"\n",
    "# prices['O-to-C'] == prices['MaxOC_Prev10'\n",
    "# #Code for Breakout condition \"has a body that is at least 100% longer than the average of the previous 20 candles\"\n",
    "# prices['OC-%-from-20D-Mean'] >= 100.0\n",
    "# #Code for Breakout condition \"has a volume that is at least 50% higher than the average of the previous 20 candles\"\n",
    "# prices['Volume-%-from-20D-Mean'] >= 50.0\n",
    "                           \n",
    "#Putting it all together \n",
    "condition = (prices['O-to-C'] >= 0.0) & (prices['O-to-C'] == prices['MaxOC_Prev10']) & (prices['OC-%-from-20D-Mean'] >= 100.0) & (prices['Volume-%-from-20D-Mean'] >= 50.0) \n",
    "breakouts = prices[condition]\n",
    "breakouts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b4eabf-d88d-4b1f-9ce0-26dfeac4dab3",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### disney only has 202 breakout points going back to 1970 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c90d783-b68b-44e2-b3dd-b48ac6e3bba7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create Breakout Column for Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124c4c28-69be-4e1a-901d-9e1b295abdef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Putting it all together \n",
    "condition = (prices['O-to-C'] >= 0.0) & (prices['O-to-C'] == prices['MaxOC_Prev10']) & (prices['OC-%-from-20D-Mean'] >= 100.0) & (prices['Volume-%-from-20D-Mean'] >= 50.0) \n",
    "breakouts = prices[condition]\n",
    "breakouts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d339ed-2451-4ce0-80e0-273fadaf9ee3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create Y - Breakout Signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466b3bd5-649e-4546-8694-10aee8364f9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Creating a new column so we can assign binary values\n",
    "prices['breakout_signal'] = np.where(condition, 1, 0)\n",
    "prices.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951cee2b-146e-48b9-87d9-d5b35fc49b46",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Clean Dataset Function for X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89df79a1-192d-4ca6-830e-db038a31a468",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# gets rid of null and infinite values \n",
    "def clean_dataset(df):\n",
    "    assert isinstance(df, pd.DataFrame), \"df needs to be a pd.DataFrame\"\n",
    "    df.dropna(inplace=True)\n",
    "    indices_to_keep = ~df.isin([np.nan, np.inf, -np.inf]).any(axis=1)\n",
    "    return df[indices_to_keep].astype(np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed9ba45-388e-43b3-9279-5b2a501afb41",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Prepare X and Y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99afc030-5e7f-4ecb-ad0a-1bce8da2cf45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create raw X and Y \n",
    "X = prices[['O-to-C', 'OC-20D-Mean', 'Volume-20D-Mean', 'MaxOC_Prev10', 'Volume-%-from-20D-Mean', 'OC-%-from-20D-Mean']]\n",
    "y = prices['breakout_signal'] \n",
    "\n",
    "#clean data\n",
    "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "X.fillna(999, inplace=True)\n",
    "\n",
    "# train test split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    random_state=1, \n",
    "                                                    stratify=y)\n",
    "#scaling \n",
    "# Instantiate a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the training data to the standard scaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Transform the training data using the scaler\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "\n",
    "# Transform the testing data using the scaler\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53711291-41e4-4674-818f-b7cc2a57db89",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354eafd5-ef60-4267-b534-6a9e9b510c53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Model\n",
    "classifier = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "#Fit\n",
    "classifier.fit(X_train, y_train) \n",
    "#Predict\n",
    "predictions = classifier.predict(X_test)\n",
    "#evaluate \n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa7fdea-8783-443f-9ece-ef88254478c8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### although our model has a high global accuracy its clear that it cannot predict breakouts for disney "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c64a8b-13a0-43c5-b1e8-ddcfaf589e8e",
   "metadata": {},
   "source": [
    "# Are we using the wrong model? Let's try XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d5a461-061f-48cf-a623-74b960e8f616",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LabelEncoder which is specific to XGB \n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "\n",
    "#Model\n",
    "classifier = xgb.XGBClassifier() ## notice different classifier \n",
    "#Fit\n",
    "classifier.fit(X_train, y_train)\n",
    "#Predict\n",
    "predictions = classifier.predict(X_test)\n",
    "#evaluate \n",
    "y_pred = classifier.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8199bb-3081-4b80-af17-5430677e7e76",
   "metadata": {},
   "source": [
    "### we noticed marked improvement by simply changing the classifier to XGBoost. This is where you talk about the performance history of XGBoost in OSS data science competitions on Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e6edcc-44ac-436c-b64b-3a9657429026",
   "metadata": {},
   "source": [
    "# We know we have Imbalanced Class issue, will under or over sampling help improve XGBoost results? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2056476d-333d-4635-9775-6acd8ba24d8d",
   "metadata": {},
   "source": [
    "## Create X and Y Over and Under Sampled Versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25dda58d-c1f9-4dd9-9c67-c652137cb8bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Instantiate the RandomOverSampler instance\n",
    "random_oversampler = RandomOverSampler(random_state=1)\n",
    "\n",
    "# create X and Y Oversampled\n",
    "X_over, y_over = random_oversampler.fit_resample(X_train, y_train)\n",
    "\n",
    "\n",
    "# Instantiate the RandomUnderSampler instance\n",
    "rus = RandomUnderSampler(random_state=1)\n",
    "\n",
    "# create X and Y Undersampled \n",
    "X_under, y_under = rus.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31f9182-04d3-403f-b9ec-7386c81153af",
   "metadata": {},
   "source": [
    "## Oversampling Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f249db-5bfa-41e4-8367-003510eb28f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LabelEncoder which is specific to XGB \n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "\n",
    "#Model\n",
    "classifier = xgb.XGBClassifier() \n",
    "#Fit\n",
    "classifier.fit(X_over, y_over)\n",
    "#Predict\n",
    "predictions = classifier.predict(X_test)\n",
    "#evaluate \n",
    "y_pred = classifier.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574013c6-439e-4297-9b29-aa40d665dca3",
   "metadata": {},
   "source": [
    "## Undersampling Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665b6a34-50ce-4786-8a4d-1de26b2d1335",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LabelEncoder which is specific to XGB \n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "\n",
    "#Model\n",
    "classifier = xgb.XGBClassifier() \n",
    "#Fit\n",
    "classifier.fit(X_under, y_under )\n",
    "#Predict\n",
    "predictions = classifier.predict(X_test)\n",
    "#evaluate \n",
    "y_pred = classifier.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff566cbc-6961-46b8-b44c-07e3ec5b5050",
   "metadata": {},
   "source": [
    "#### After testing different combinations of sampling and classifiers, here are the results: \n",
    "###### 1. XGB Over\n",
    "###### 2. XGB\n",
    "###### 3. XGB Under\n",
    "###### 4. LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63fcebd-4676-4a26-90b7-ae9597c1d3b8",
   "metadata": {},
   "source": [
    "# let's try a decision tree!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815fd7bc-bc5d-4dda-a2c2-fbd997631756",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Model\n",
    "classifier = DecisionTreeClassifier()\n",
    "#Fit\n",
    "classifier.fit(X_over, y_over)\n",
    "#Predict\n",
    "predictions = classifier.predict(X_test)\n",
    "#evaluate \n",
    "y_pred = classifier.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011b9773-97f4-4805-83a0-cbc0f28dbbc7",
   "metadata": {},
   "source": [
    "# let's try a support vector classifier!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04d1b8a-ea2a-488e-9fff-5278e9f710cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Model\n",
    "classifier = SVC()\n",
    "#Fit\n",
    "classifier.fit(X_over, y_over)\n",
    "#Predict\n",
    "predictions = classifier.predict(X_test)\n",
    "#evaluate \n",
    "y_pred = classifier.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
